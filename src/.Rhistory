1e6
1e6/10
1e6/1000
1e4
source("~/Desktop/many_analysts/many_analysts_sim.R")
thresholds = c(0.01, 0.01, 0.001)
library(tidyverse)
library(combinat)
thresholds = c(0.01, 0.01, 0.001)
sample_size = c(1e4, 1e5, 1e6)
generate_data = function(n = 10000, predictors = 30, n_var = 5, noise_mean = 0, noise_sd = 1){
}
source("~/Desktop/many_analysts/many_analysts_sim.R")
library(tidyverse)
library(combinat)
### This simulation demonstrates the Rashomon effect
### More sample size means fewer models in the rashomon set for the same epsilon
# Function to generate synthetic data and evaluate subset selection models
generate_data <- function(sample_size, threshold, predictors = 30, n_var = 5,
seed = NULL, max_models = 10000) {
if (!is.null(seed)) set.seed(seed)
# Generate true coefficients - make them smaller and more numerous to increase overlap
true_coeffs <- rep(0, predictors)
# Make many variables weakly predictive (creates more model ambiguity)
true_coeffs[1:15] <- c(0.8, -0.6, 0.9, -0.4, 0.7, -0.5, 0.6, -0.3,
0.5, -0.7, 0.4, -0.8, 0.3, -0.4, 0.6)
# Generate predictors with substantial correlation structure
X <- matrix(rnorm(sample_size * predictors), nrow = sample_size, ncol = predictors)
# Create more extensive correlation structure
correlation_strength <- 0.6  # Increased correlation
for(i in 1:10) {
for(j in 1:3) {
if(i + j*5 <= predictors) {
X[, i + j*5] <- correlation_strength * X[, i] +
sqrt(1 - correlation_strength^2) * X[, i + j*5]
}
}
}
# Generate response with noise scaled to sample size to maintain signal-to-noise ratio
noise_sd <- 2 + 0.5 * log(sample_size/1000)  # Slightly increase noise with sample size
y <- X %*% true_coeffs + rnorm(sample_size, sd = noise_sd)
# Create all possible 5-variable combinations (sample more for larger datasets)
all_combinations <- combn(predictors, n_var, simplify = FALSE)
# Adjust sampling based on sample size - larger samples get more models tested
models_to_test <- min(length(all_combinations),
max_models * (1 + log10(sample_size/1000)))
if (length(all_combinations) > models_to_test) {
sampled_indices <- sample(length(all_combinations), models_to_test)
all_combinations <- all_combinations[sampled_indices]
}
cat("Evaluating", length(all_combinations), "models for sample size", sample_size, "\n")
# Evaluate each model with regularization for numerical stability
results <- map_dfr(all_combinations, function(vars) {
# Fit linear regression with slight regularization for stability
X_subset <- X[, vars, drop = FALSE]
# Add small ridge penalty for numerical stability
ridge_lambda <- 0.001
XtX <- t(X_subset) %*% X_subset + ridge_lambda * diag(ncol(X_subset))
Xty <- t(X_subset) %*% y
# Solve normal equations
coeffs <- solve(XtX, Xty)
intercept <- mean(y) - mean(X_subset %*% coeffs)
# Calculate predictions and RSS
y_pred <- intercept + X_subset %*% coeffs
rss <- sum((y - y_pred)^2)
tibble(
variables = list(vars),
rss = rss,
coefficients = list(as.numeric(coeffs)),
intercept = intercept
)
})
# Find best RSS
best_rss <- min(results$rss)
# Find models within threshold
threshold_rss <- best_rss * (1 + threshold)
rashomon_set <- results[results$rss <= threshold_rss, ]
# Create summary
summary_stats <- list(
sample_size = sample_size,
threshold = threshold,
total_models = nrow(results),
best_rss = best_rss,
threshold_rss = threshold_rss,
rashomon_set_size = nrow(rashomon_set),
rashomon_proportion = nrow(rashomon_set) / nrow(results)
)
return(list(
summary = summary_stats,
rashomon_models = rashomon_set,
all_results = results
))
}
# Function to analyze variable importance across Rashomon set
analyze_variable_importance <- function(rashomon_models, n_predictors = 30) {
# Count how often each variable appears
var_counts <- rep(0, n_predictors)
for(i in 1:nrow(rashomon_models)) {
vars <- rashomon_models$variables[[i]]
var_counts[vars] <- var_counts[vars] + 1
}
# Calculate coefficients summary for each variable
var_coeff_summary <- map_dfr(1:n_predictors, function(var_idx) {
# Find models containing this variable
models_with_var <- map_lgl(rashomon_models$variables, ~ var_idx %in% .x)
if (sum(models_with_var) == 0) {
return(tibble(variable = var_idx, count = 0, mean_coeff = NA,
sd_coeff = NA, min_coeff = NA, max_coeff = NA))
}
# Extract coefficients for this variable
coeffs <- map_dbl(which(models_with_var), function(model_idx) {
vars <- rashomon_models$variables[[model_idx]]
coeff_vec <- rashomon_models$coefficients[[model_idx]]
pos_in_model <- which(vars == var_idx)
coeff_vec[pos_in_model]
})
tibble(
variable = var_idx,
count = sum(models_with_var),
mean_coeff = mean(coeffs),
sd_coeff = sd(coeffs),
min_coeff = min(coeffs),
max_coeff = max(coeffs)
)
})
return(var_coeff_summary)
}
# Run simulation across different sample sizes and thresholds
run_rashomon_simulation <- function() {
# Simulation parameters - adjusted for better Rashomon effect demonstration
sample_sizes <- c(500, 2000, 8000, 20000)
thresholds <- c(0.001, 0.005, 0.01, 0.02)
# Run simulation
simulation_results <- expand_grid(
sample_size = sample_sizes,
threshold = thresholds
) %>%
mutate(
results = map2(sample_size, threshold,
~generate_data(.x, .y, seed = 42, max_models = 8000))
) %>%
mutate(
rashomon_size = map_dbl(results, ~.x$summary$rashomon_set_size),
rashomon_proportion = map_dbl(results, ~.x$summary$rashomon_proportion),
best_rss = map_dbl(results, ~.x$summary$best_rss),
total_models = map_dbl(results, ~.x$summary$total_models)
)
return(simulation_results)
}
# Visualize results
plot_rashomon_results <- function(sim_results) {
# Plot 1: Rashomon set size vs sample size
p1 <- sim_results %>%
ggplot(aes(x = sample_size, y = rashomon_size, color = factor(threshold))) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_x_log10(labels = scales::comma) +
scale_color_viridis_d(name = "Threshold") +
labs(
title = "Rashomon Set Size vs Sample Size",
subtitle = "Larger samples â†’ More models within performance threshold",
x = "Sample Size (log scale)",
y = "Number of Models in Rashomon Set"
) +
theme_minimal()
# Plot 2: Proportion in Rashomon set
p2 <- sim_results %>%
ggplot(aes(x = sample_size, y = rashomon_proportion, color = factor(threshold))) +
geom_line(size = 1.2) +
geom_point(size = 3) +
scale_x_log10(labels = scales::comma) +
scale_y_continuous(labels = scales::percent) +
scale_color_viridis_d(name = "Threshold") +
labs(
title = "Proportion of Models in Rashomon Set",
x = "Sample Size (log scale)",
y = "Proportion of Models Within Threshold"
) +
theme_minimal()
return(list(size_plot = p1, proportion_plot = p2))
}
# Example of extracting different "stories" from Rashomon set
extract_different_stories <- function(rashomon_models, n_stories = 3) {
# Sample different models from Rashomon set
if (nrow(rashomon_models) < n_stories) {
selected_indices <- 1:nrow(rashomon_models)
} else {
selected_indices <- sample(nrow(rashomon_models), n_stories)
}
stories <- map(selected_indices, function(idx) {
vars <- rashomon_models$variables[[idx]]
coeffs <- rashomon_models$coefficients[[idx]]
intercept <- rashomon_models$intercept[[idx]]
rss <- rashomon_models$rss[[idx]]
# Create equation string
terms <- paste0(round(coeffs, 2), "*x", vars)
equation <- paste("y =", round(intercept, 2), "+", paste(terms, collapse = " + "))
equation <- str_replace_all(equation, "\\+ -", "- ")
list(
model_index = idx,
variables = vars,
equation = equation,
rss = rss
)
})
return(stories)
}
# Run the simulation
cat("Running Rashomon Effect Simulation...\n")
results <- run_rashomon_simulation()
# Display summary with better formatting
cat("\nRashomon Set Sizes by Sample Size and Threshold:\n")
results %>%
select(sample_size, threshold, total_models, rashomon_size, rashomon_proportion) %>%
arrange(sample_size, threshold) %>%
mutate(
rashomon_proportion = paste0(round(rashomon_proportion * 100, 1), "%")
) %>%
print()
# Show the key insight: larger samples -> larger Rashomon sets
cat("\nKey Insight - Rashomon Set Size vs Sample Size:\n")
results %>%
group_by(threshold) %>%
arrange(sample_size) %>%
select(threshold, sample_size, rashomon_size) %>%
print()
# Create plots
plots <- plot_rashomon_results(results)
print(plots$size_plot)
print(plots$proportion_plot)
# Example: Show different "stories" for largest sample size
largest_sample_result <- results %>%
filter(sample_size == max(sample_size), threshold == 0.01) %>%
pull(results) %>%
.[[1]]
stories <- extract_different_stories(largest_sample_result$rashomon_models, 3)
cat("\nExample of different 'stories' from the same data:\n")
for (i in seq_along(stories)) {
cat("Story", i, ":", stories[[i]]$equation, "\n")
cat("RSS:", round(stories[[i]]$rss, 2), "\n")
cat("Variables used: x", paste(stories[[i]]$variables, collapse = ", x"), "\n\n")
}
# Analyze variable importance
var_importance <- analyze_variable_importance(largest_sample_result$rashomon_models)
cat("Variable importance in Rashomon set (top 10):\n")
var_importance %>%
filter(count > 0) %>%
arrange(desc(count)) %>%
head(10) %>%
print()
View(results)
head(results)
write.csv(results, file = '../data/results.csv')
write.csv(results, file = '../data/results.csv')
setwd("~/Desktop/many_analysts")
write.csv(results, file = '../data/results.csv')
write.csv(results, file = '../data/results.csv')
write.csv(results, file = '../data/results.csv', row.names = FALSE)
getwd()
# save as csv
write.csv(results, file = '../data/results.csv', row.names = FALSE)
setwd("~/Desktop/many_analysts/src")
# save as csv
write.csv(results, file = '../data/results.csv', row.names = FALSE)
typeof(results)
# save as csv
write.csv(results, file = '../data/results.csv', row.names = FALSE)
View(results)
